{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6287bbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5411764705882353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.51      0.95      0.67        39\n",
      "     Neutral       0.00      0.00      0.00        17\n",
      "    Positive       0.69      0.31      0.43        29\n",
      "\n",
      "    accuracy                           0.54        85\n",
      "   macro avg       0.40      0.42      0.37        85\n",
      "weighted avg       0.47      0.54      0.45        85\n",
      "\n",
      "col_0      Negative  Positive\n",
      "sentiment                    \n",
      "Negative         37         2\n",
      "Neutral          15         2\n",
      "Positive         20         9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Needed for tfidf command below\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "#Get the dataframe of tweets\n",
    "df = pd.read_csv('data\\\\tweets_all.csv')\n",
    "\n",
    "#Split into three df's based on topic\n",
    "df_politics = df.loc[df['topic'].isin([\"Sinn Fein\", \"Qanon\", \"Varadkar\"])]\n",
    "df_TV = df.loc[df['topic'].isin([\"Eastenders\", \"Tommy Tiernan\", \"Eoghan McDermott\"])]\n",
    "df_others = df.loc[df['topic'].isin([\"Pancakes\", \"Burren\", \"Daniel Kinahan\", \"Shamrock Rovers\"])]\n",
    "\n",
    "\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df['clean_text'], df['sentiment']\n",
    "\n",
    "#Using model on all tweets\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,1))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf204239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6470588235294118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.64      0.90      0.74        39\n",
      "     Neutral       0.33      0.12      0.17        17\n",
      "    Positive       0.75      0.62      0.68        29\n",
      "\n",
      "    accuracy                           0.65        85\n",
      "   macro avg       0.57      0.55      0.53        85\n",
      "weighted avg       0.61      0.65      0.61        85\n",
      "\n",
      "col_0      Negative  Neutral  Positive\n",
      "sentiment                             \n",
      "Negative         35        2         2\n",
      "Neutral          11        2         4\n",
      "Positive          9        2        18\n"
     ]
    }
   ],
   "source": [
    "#Using model on all tweets - 2 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df_all['clean_text'], df_all['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,2))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de010f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7794117647058824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.95      0.83        39\n",
      "    Positive       0.89      0.55      0.68        29\n",
      "\n",
      "    accuracy                           0.78        68\n",
      "   macro avg       0.81      0.75      0.76        68\n",
      "weighted avg       0.80      0.78      0.77        68\n",
      "\n",
      "col_0      Negative  Positive\n",
      "sentiment                    \n",
      "Negative         37         2\n",
      "Positive         13        16\n"
     ]
    }
   ],
   "source": [
    "#Using model on all tweets - 3 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df_all['clean_text'], df_all['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,3))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56054190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6538461538461539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.65      1.00      0.79        17\n",
      "     Neutral       0.00      0.00      0.00         7\n",
      "    Positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.22      0.33      0.26        26\n",
      "weighted avg       0.43      0.65      0.52        26\n",
      "\n",
      "col_0      Negative\n",
      "sentiment          \n",
      "Negative         17\n",
      "Neutral           7\n",
      "Positive          2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Using model on politics tweets...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df_politics['clean_text'], df_politics['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,1))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88c13d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5769230769230769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.64      0.82      0.72        17\n",
      "     Neutral       0.33      0.14      0.20         7\n",
      "    Positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.58        26\n",
      "   macro avg       0.32      0.32      0.31        26\n",
      "weighted avg       0.51      0.58      0.52        26\n",
      "\n",
      "col_0      Negative  Neutral  Positive\n",
      "sentiment                             \n",
      "Negative         14        2         1\n",
      "Neutral           6        1         0\n",
      "Positive          2        0         0\n"
     ]
    }
   ],
   "source": [
    "#Using model on politics tweets - 2 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df_politics['clean_text'], df_politics['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,2))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa7f53b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6923076923076923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      0.88      0.79        17\n",
      "     Neutral       0.60      0.43      0.50         7\n",
      "    Positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.44      0.44      0.43        26\n",
      "weighted avg       0.63      0.69      0.65        26\n",
      "\n",
      "col_0      Negative  Neutral\n",
      "sentiment                   \n",
      "Negative         15        2\n",
      "Neutral           4        3\n",
      "Positive          2        0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Using model on politics tweets - 3 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df_politics['clean_text'], df_politics['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,3))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323e1588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956521739130435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.50      0.62         8\n",
      "     Neutral       1.00      0.25      0.40         4\n",
      "    Positive       0.65      1.00      0.79        11\n",
      "\n",
      "    accuracy                           0.70        23\n",
      "   macro avg       0.82      0.58      0.60        23\n",
      "weighted avg       0.76      0.70      0.66        23\n",
      "\n",
      "col_0      Negative  Neutral  Positive\n",
      "sentiment                             \n",
      "Negative          4        0         4\n",
      "Neutral           1        1         2\n",
      "Positive          0        0        11\n"
     ]
    }
   ],
   "source": [
    "#Using model on TV tweets...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df_TV['clean_text'], df_TV['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,1))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4942ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8260869565217391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.75      0.86         8\n",
      "     Neutral       1.00      0.50      0.67         4\n",
      "    Positive       0.73      1.00      0.85        11\n",
      "\n",
      "    accuracy                           0.83        23\n",
      "   macro avg       0.91      0.75      0.79        23\n",
      "weighted avg       0.87      0.83      0.82        23\n",
      "\n",
      "col_0      Negative  Neutral  Positive\n",
      "sentiment                             \n",
      "Negative          6        0         2\n",
      "Neutral           0        2         2\n",
      "Positive          0        0        11\n"
     ]
    }
   ],
   "source": [
    "#Using model on TV tweets - 2 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df_TV['clean_text'], df_TV['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,2))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b228e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8260869565217391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.88      0.93         8\n",
      "     Neutral       1.00      0.25      0.40         4\n",
      "    Positive       0.73      1.00      0.85        11\n",
      "\n",
      "    accuracy                           0.83        23\n",
      "   macro avg       0.91      0.71      0.73        23\n",
      "weighted avg       0.87      0.83      0.80        23\n",
      "\n",
      "col_0      Negative  Neutral  Positive\n",
      "sentiment                             \n",
      "Negative          7        0         1\n",
      "Neutral           0        1         3\n",
      "Positive          0        0        11\n"
     ]
    }
   ],
   "source": [
    "#Using model on TV tweets - 3 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df_TV['clean_text'], df_TV['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,3))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1df15a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5135135135135135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.47      0.64      0.55        14\n",
      "     Neutral       0.00      0.00      0.00         6\n",
      "    Positive       0.56      0.59      0.57        17\n",
      "\n",
      "    accuracy                           0.51        37\n",
      "   macro avg       0.34      0.41      0.37        37\n",
      "weighted avg       0.43      0.51      0.47        37\n",
      "\n",
      "col_0      Negative  Positive\n",
      "sentiment                    \n",
      "Negative          9         5\n",
      "Neutral           3         3\n",
      "Positive          7        10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Using model on others tweets\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df_others['clean_text'], df_others['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,1))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e71ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6216216216216216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.71      0.69        14\n",
      "     Neutral       0.00      0.00      0.00         6\n",
      "    Positive       0.59      0.76      0.67        17\n",
      "\n",
      "    accuracy                           0.62        37\n",
      "   macro avg       0.42      0.49      0.45        37\n",
      "weighted avg       0.52      0.62      0.57        37\n",
      "\n",
      "col_0      Negative  Positive\n",
      "sentiment                    \n",
      "Negative         10         4\n",
      "Neutral           1         5\n",
      "Positive          4        13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Using model on others tweets - 2 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df_others['clean_text'], df_others['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,2))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48db0393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6486486486486487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      0.71      0.71        14\n",
      "     Neutral       0.00      0.00      0.00         6\n",
      "    Positive       0.61      0.82      0.70        17\n",
      "\n",
      "    accuracy                           0.65        37\n",
      "   macro avg       0.44      0.51      0.47        37\n",
      "weighted avg       0.55      0.65      0.59        37\n",
      "\n",
      "col_0      Negative  Positive\n",
      "sentiment                    \n",
      "Negative         10         4\n",
      "Neutral           1         5\n",
      "Positive          3        14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Using model on others tweets - 3 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "X,y = df_others['clean_text'], df_others['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "# x_train = df_politics['clean_text']\n",
    "# x_test = df_TV['clean_text']\n",
    "# y_train = df_politics['sentiment']\n",
    "# y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,3))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a20fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00        38\n",
      "     Neutral       1.00      1.00      1.00        21\n",
      "    Positive       1.00      1.00      1.00        53\n",
      "\n",
      "    accuracy                           1.00       112\n",
      "   macro avg       1.00      1.00      1.00       112\n",
      "weighted avg       1.00      1.00      1.00       112\n",
      "\n",
      "col_0      Negative  Neutral  Positive\n",
      "sentiment                             \n",
      "Negative         38        0         0\n",
      "Neutral           0       21         0\n",
      "Positive          0        0        53\n"
     ]
    }
   ],
   "source": [
    "#Using model on others tweets - 3 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "#X,y = df_others['clean_text'], df_others['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "x_train = df_TV['clean_text']\n",
    "x_test = df_TV['clean_text']\n",
    "y_train = df_TV['sentiment']\n",
    "y_test = df_TV['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,3))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3abdfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6785714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.64      1.00      0.78        32\n",
      "     Neutral       1.00      0.25      0.40        20\n",
      "    Positive       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.68        56\n",
      "   macro avg       0.88      0.50      0.53        56\n",
      "weighted avg       0.79      0.68      0.62        56\n",
      "\n",
      "col_0      Negative  Neutral  Positive\n",
      "sentiment                             \n",
      "Negative         32        0         0\n",
      "Neutral          15        5         0\n",
      "Positive          3        0         1\n"
     ]
    }
   ],
   "source": [
    "#Using model on just SF tweets - 1 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "#X,y = df_others['clean_text'], df_others['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "x_train = df2['clean_text']\n",
    "x_test = df2['clean_text']\n",
    "y_train = df2['sentiment']\n",
    "y_test = df2['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,1))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f5d76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      1.00      0.86        28\n",
      "     Neutral       1.00      0.27      0.43        11\n",
      "    Positive       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.59      0.42      0.43        40\n",
      "weighted avg       0.80      0.78      0.72        40\n",
      "\n",
      "col_0      Negative  Neutral\n",
      "sentiment                   \n",
      "Negative         28        0\n",
      "Neutral           8        3\n",
      "Positive          1        0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Using model on just Varadkar tweets - 1 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "#X,y = df_others['clean_text'], df_others['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "x_train = df1['clean_text']\n",
    "x_test = df1['clean_text']\n",
    "y_train = df1['sentiment']\n",
    "y_test = df1['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,1))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e8b18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7878787878787878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.78      1.00      0.88        25\n",
      "     Neutral       0.00      0.00      0.00         5\n",
      "    Positive       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.79        33\n",
      "   macro avg       0.59      0.44      0.46        33\n",
      "weighted avg       0.68      0.79      0.71        33\n",
      "\n",
      "col_0      Negative  Positive\n",
      "sentiment                    \n",
      "Negative         25         0\n",
      "Neutral           5         0\n",
      "Positive          2         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Using model on just Qanon tweets - 1 n-grams...\n",
    "\n",
    "#X is the cleaned tweet and y is the sentiment\n",
    "#X,y = df_others['clean_text'], df_others['sentiment']\n",
    "\n",
    "#Split into train and test data\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32, stratify=y)\n",
    "#If we want to use one model on a different set of tweets...\n",
    "x_train = df3['clean_text']\n",
    "x_test = df3['clean_text']\n",
    "y_train = df3['sentiment']\n",
    "y_test = df3['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy, token_pattern=None, ngram_range=(1,1))\n",
    "\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "nb_clf =  MultinomialNB(alpha=0.005)\n",
    "\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "print(nb_clf.score(x_test, y_test))\n",
    "\n",
    "y_pred = nb_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c61a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
